%% This is an example first chapter.  You should put chapter/appendix that you
%% write into a separate file, and add a line \include{yourfilename} to
%% main.tex, where `yourfilename.tex' is the name of the chapter/appendix file.
%% You can process specific files by typing their names in at the 
%% \files=
%% prompt when you run the file main.tex through LaTeX.
\chapter{Methods}
\section{Simulation}
There exist various types of simulators for di↵erent biochemical reaction systems. Conventionally, biochemical reaction systems are described using concentrations as state variables and treated with ordinary differential equations (ODE). This approach is deterministic. It follows a well-mixed hypothesis, assuming either the molecule distribution is in spatially homogeneous or their diffusion occurs much faster than the reactions. Such an assumption is suitable for models without spatial concerns, for example, gene networks, and metabolic networks. COPASI~\cite{} is software widely used for the ODE models.

Deterministic spatial models can be described with reaction-di↵usion equations. These equations are partial differential equations (PDE) that consist of reaction terms and diffusion terms. The Virtual Cell~\cite{} is software for simulating the reaction-diffusion systems. For stochastic models, in which state variables are discrete molecule numbers instead of continuous concentrations, the Gillespie algorithm~\cite{}, and its variations are used widely for simulations. The algorithm is exact regarding to chemical master equations. However it becomes computationally demanding when simulating large reaction systems.

When models are both stochastic and spatial, there are a few simulation approaches with varying spatial resolution. Some divide the whole volume and perform Gillespie algorithm in each subvolume. However, the way of dividing the volume affects the simulation accuracy. Programs including MesoRD~\cite{} are for this type of simulations. A more accurate approach is to treat molecules individually as particles. In this case, space is not discretized but continuous. Molecules are particle-like objects. Their diffusion follows statistics of Brownian motion and their reaction events depend on molecular collisions. Software such as Smoldyn~\cite{} and MCell~\cite{} are particle-based simulators.

\subsection{Smoldyn}

For the model described here, we have chosen to use Smoldyn. Smoldyn is a stochastic simulator for discrete time continuous space systems. It simulates the Brownian motion of molecules and diffusion-limited chemical reactions. The molecules are point-like and do not take up physical space. Details such as rotation, orientation, intermolecular forces are not considered. The particle-based approach in Smoldyn provides a microsecond level temporal resolution and a nanometer level spatial accuracy. In Smoldyn, only molecules of interest are explicitly included in the simulation system. Although solvent and other molecules are assumed to collide constantly with the molecules of interest, their effects are treated implicitly as a↵ecting the diffusion of molecules in the system.

Smoldyn uses a fixed time step. An appropriate time step value is selected so that in one time step the probability of having the fastest first order reaction occur is at most 0.1. With this assumption, during a time step, whether a first order reaction occurs or does not occur can be viewed as a binary event, which follows a Poisson distribution. For three-dimensional isotropic Brownian diffusions, a mean square distance is calculated for each diffusible molecule for each spatial coordinate following the equation $MSD = \sqrt{2\times rv\timesdt}$, where $rv$ is a unit Gaussian random variable and $dt$ is the time step. The MSD is calculated at each iteration and added to each diffusible molecule.

The reactions built into the Smoldyn simulator are mostly elementary reactions and can be at most second order. First order reactions such as unbindings and (de)phosphorylations are modeled as Poisson processes with event rates equal the corresponding rate constant parameter measured from experiments. Probability is calculated for each reaction using equation $Pr=e^{-rate\timesdt}$. A random variable is generated and compared to the $Pr$ value as a criterion to decide whether to proceed the particular reaction ($rv<Pr$). 

Since molecules in Smoldyn do not possess physical volume, collisions are assumed to occur as long as two reactants are sufficiently close. The criterion for the closeness is a binding radius, which is calculated in Smoldyn based on simulation time step, reactants diffusion coeffcients, the kinetic rate constant, and the possible reversal unbinding reactions. Reactants within the binding radius are allowed to bind. For a particular second order reaction, the binding radius is essentially a numerical solution of radial distribution function (RDF) for the Collins and Kimball model~\cite{Andrews}, allowing the dynanimcs of most biochemical reactions to be simulated consistent wit mass action theory.

The workflow of Smoldyn within a time step is as follow:
diffusion -> surface interaction check -> reactions -> surface interaction check -> simulation time update

Molecules are grouped into lists. By default, there is a diffusion list which contains all diffusible molecules. At each time step iteration, the simulator loops over the diffusion list and updates each molecule position by computing a random diffusion step. Then the simulator checks surface interactions for molecules with updated locations in case molecules move across surfaces that are reflective, absorptive, or jumping. In general, whenever molecules update positions due to diffusion or reactions, the simulator examines the possible interactions between molecules and compartment surfaces to see if boundary conditions are violated. Reactions simulated include zeroth order, first order, and second order reactions. In Smoldyn, it is arbitrary that lower order reactions are examined before higher ones. This arrangement however introduces bias. Smoldyn processes reactions by checking molecules in lists. If a molecule is involved in a zeroth or first order reaction, the reaction probability is used to decide whether the particular reaction occurs or not. For second order reactions, the criterion for a reaction to occur is the binding radius. Binding or unbinding may change a molecule’s position. After the reaction stage, the simulator checks the surface interaction again for molecules that changed locations.


\subsection{Modifications to Smoldyn}
Our work requires modeling reactions between complex molecules, and this leads us to develop more sophisticated molecule and reaction features than available in the original Smoldyn. In our customized version, molecules are not just point-like objects. Complex molecules, such as CaMKII, consist of multiple subunits which can have independent reactions. Consequently, we have modified Smoldyn so that subunits take distinct physical locations. For diffusion, the position change is calculated for one subunit, and the other subunits shift their positions accordingly.

Each complex has multiple subunits or molecules, and each molecule has at least one binding site. The states of binding sites are implemented as bit vectors. A value 1 means a site is bound or phosphorylated; whereas a value 0 means a site is unbound or unphosphorylated. Hence, each molecule can have $2^{sites_number}$ states. Depending on the binding situation of the reactant(s), there can be a set of possible reaction choices, which are chained in an arbitrary sequence. The customized simulator picks one reaction from the sequence randomly and checks the reactant(s) against the probability (for first order reactions) or the binding radius (for second order reactions). If the picked reaction gets rejected, the simulator continues to the next reaction in the sequence until all reactions are examined or one passes the check. Using random picking, we avoid the potential bias caused by a fixed sequence of choices.

To illustrate, suppose we have a calmodulin molecule with no calcium ions bound (apoCaM) and one nearby calcium ion can interact with either an N lobe site or a C lobe site of calmodulin. The two reaction choices can be expressed:
\begin{quote}
\begin{verbatim}
cam{N1==0, N2==0, C1==0, C2==0, Ng==0, K==0, Kp==0} + ca{cam==0} -> cam[N1=1]~ca[cam=1]
cam{N1==0, N2==0, C1==0, C2==0, Ng==0, K==0, Kp==0} + ca{cam==0} -> cam[C1=1]~ca[cam=1]
\end{quote}
\end{verbatim}

In the equations, '{}' represents the states at relevant binding sites and also can be considered as the precondition for the reaction to occur; '+' represents binding; '$\sim$' is a bond formed between molecules; '[]' codes for sites that are updated in products. The binding state vector of the binding states of the CaM molecule is ’0000000’, which equals 0. This binding state value is paired with the identity of the CaM molecule, resulting in the first key. Likewise, a second key value can be calculated for the Ca\textsuperscript{2+} ion. The simulator uses the key pair to look up a reaction choice in pre-loaded reaction table, which is a hash table with a key pair input. The lookup result is the sequence of two reactions which are listed above. Then one reaction is picked randomly. Since this reaction is second order, if the distance between the reactants is less than the binding radius, the two reactants bind accordingly, with sites involved in the binding updated to new values by updating the vectors. Otherwise, the simulator continues to the next reaction in the sequence. To speed up simulations, the model space volume is pre-divided into unit boxes during model initiation. Only molecule pairs located in the same box or neighbor boxes are considered as nearby for reaction checking.

\subsection{Categories of reactions}
In the original Smoldyn, two reactants bind and collapse into one product. The reactants are removed from the system, and a product molecule is generated anew. As a result, the product carries a different serial number, making it difficult to track the reaction history of a particular molecule. In the customized version, all reactions are described at the binding site level. When two reactants bind, their physical positions are connected to each other. Thus the molecules are bound without being replaced by newly generated molecules, making it possible for the simulator to track a molecule's reaction history. When two molecules are bound, one is considered as dominant to determine the overall diffusion coefficient. For example, when Ca\textsuperscript{2+} and CaM are bound, the attached Ca\textsuperscript{2+} molecule diffuse with the CaM diffusion rate; similarly, CaM bound to a CaMKII subunit will diffuse with the CaMKII.

*** can be elaborated
A CaMKII holoenzyme is an example of a complex composed of two 6-subunits rings. Each subunit is a molecule containing binding sites for CaM and phosphorylation. Each ring has a radius of approximately \SI{8}{\nm} and is separated from its direct neighbors at a fixed distance of \SI{8}{\nm} (estimated from~\cite{Gaertner:2004jk}). For simplicity, we modeled CaMKII holoenzymes as one ring of 6 subunits. 
***

Reactions are categorized by the number of reactants and products. Below are the reaction types included in the model.
1) A->B
An example reaction is that a phosphorylated CaMKII subunit without CaM bound becomes
dephosphorylated, e.g.,
camkii{P==1,cam==0} -> camkii[P=0].
Where P stands for the phosphate binding site and cam stands for the CaM binding site of a CaMKII subunit. Assuming abundant phosphate molecules are around, phosphate is treated implicitly, and the reaction is unimolecular and first order.

2) A$\sim$C->B$\sim$C
An example is a CaM-bound CaMKII subunit becomes dephosphorylated. Because a CaM-bound CaMKII subunit dephosphorylates at a different rate from an unbound one, this reaction is listed seperately, e.g.,
camkii{cam==1,P==1}$\sim$cam{K==1,Kp==1} -> camkii[cam=1,P=0]$\sim~$cam[K=1,Kp=0].

We can also specify the type of CaM that bound to the CaMKII subunit, if the binding state of CaM affects the phosphorylation of the CaMKII subunit. For example, for a CaMKII subunit that binds with a fully loaded CaM,
camkii{cam==1,P==0}$\sim$cam{K==1,Kp==0,N1==1,N2==1,C1==1,C2==1} -> camkii[cam=1,P=1]$\sim$cam[K=1,Kp=1].

In contrast to the first example, the reaction here is still first order but involves two molecules. The bound CaM is essential because the site named as Kp on CaM is needed to update the state. This site reflects the phosphorylation state of the CaMKII subunit bound to the cam. It is important to have this artificial Kp site because whether the bound CaMKII subunit is phosphorylated or not affects other reactions that involve the CaM. For example, a CaM bound with a phosphorylated CaMKII subunit interacts differently with a free Ca\textsuperacript{2+} ion than a CaM attached to an unphosphorylated CaMKII subunit.

Another particular case belonging to this category is the autophosphorylation reaction a CaMKII subunit, in which a subunit bound with a CaM may become phosphorylated if its neighbor subunit is bound or phosphorylated. The reaction rules are described as below:
camkii{cam==1, P==0, n.P==1, n.cam==0}$\sim$cam{K==1, Kp==0} -> camkii[P=1]$\sim$cam[Kp=1]
camkii{cam==1, P==0, n.P==0, n.cam==1}$\sim$cam{K==1, Kp==0} -> camkii[P=1]$\sim$cam[Kp=1]
camkii{cam==1, P==0, n.P==1, n.cam==1}$\sim$cam{K==1, Kp==0} -> camkii[P=1]$\sim$cam[Kp=1].
The n.P site and n.cam site of CaMKII are user-defined to reflect the binding and phosphorylation status of the neighbor subunit. The Kp site of CaM is also updated in the reaction to track the phosphorylation status of the CaMKII subunit.

3) A$\sim$B -> A + B
An example is an unbinding reaction between a CaM molecule with only the N1 site bound with a Ca\textsuperscript{2+} ion, e.g.,
cam{N1==1, N2==0, C1==0, C2==0, Ng==0, K==0, Kp==0}$\sim$ca{cam==1} -> cam[N1=0] + ca[cam=0].
After unbinding, the physical locations of the two reactants separate from each other. The binding site that previously pointed to the other molecule becomes a null pointer.

4) A+B -> A$\sim$B
An example is the one used previously describing an apoCaM binding to a free Ca\textsuperscript{2+} ion at the N1 site, e.g.,
cam{N1==0, N2==0, C1==0, C2==0, Ng==0, K==0, Kp==0} + ca{cam==1} -> cam[N1=1]$\sim$ca[cam=1].

After binding, the two reactants’ physical locations overlap and become synchronized.
Among the four reaction types, type I-III are first order and type IV is second order. Except for type I that involves one reactant, all the rest involve two reactants. Other types of reactions shown in the original Smoldyn but not listed above include A+B->C+D. This type of reaction is suitable for gas phase reactions. For solution phase as in the intracellular environment, the solvents tend to cage reactants and allow them to stay bound instead of quickly splitting up. In addition, Michaelis-Menten type reactions are commonly used to describe enzyme-substrate insteractions, especially in biochemitry studies and modeling studies adopting the ODE approach. In our case, this type of reaction, in the form of A+B<->A$\sim$B->A+C, are divided into three separate reactions:
A+B->A$\sim$B, A$\sim$B->A+B, A$\sim$B->A+C.

\subsection{}

A major part modified is the reaction implementation.

hash table
reaction expansion

The general simulation workflow in the customized Smoldyn is the same as the original version. The di↵erence is that we shu✏e the molecule lists at every iteration. Since reactions are not categorized according to the number of reactants, it is not necessarily true that first order reactions should get simulated before second order reactions. In our approach, the simulator loops through the molecule lists and for each molecule, Type I reactions proceed first. When it comes to type II-IV reactions which require two molecules, the simulator examines the unit space (a.k.a. molecule box in Smoldyn) that contains the molecule and select another molecule, which is either the same box space or a neighboring one, to guarantees the two molecules are su ciently close. The selected two molecules may already be bound. Then the simulator looks up possible reactions depending on the binding states of the molecule pair.
10
Also, at most one reaction is allowed during a time step between one pair of binding sites. For example, the simulator checks every molecule in lists in turn. If a CaM gets examined first and its N1 site binds an unexamined Ca2+ located nearby, both binding sites involved in the reaction become no longer reactive in the time step. This restriction prevents a reverse unbinding between the two molecules later when the bound Ca2+ gets examined. However, for a multi-site molecule, more than one reaction can occur within a time step. After every reaction, the reactant molecules update their binding states, so that repeat binding events are impossible. The arbitrary sequence in which molecules get examined may seem to introduce bias since molecules located first get examined earlier and then a↵ect the available reaction choices for other molecules. For example, if a CaM binds a CaMKII first, then the molecule will interact with Ca2+ with higher a nity. However, we tried to minimize the bias by shu✏ing the molecule list at every iteration. So the arbitrary ”advantage” for the precedent molecules does not accumulate.
Because binding sites are defined for molecules, a molecule can have more than one state. When searching possible reactions for the reactant(s), it is necessary to know not only the molecule identity but also the binding state. To illustrate, in the original Smoldyn, camN1C0 is considered as a molecules species with identity camN1C0; whereas in the customized Smoldyn, it consists of two molecules: a CaM with identity cam and binding state value 1, and a Ca2+ a with identity ca and binding state 1. The reaction network is implemented as a hash table using a key pair with molecule identity and binding state.
The hash table implementation followed a g_hash_table package included in the GLib library, an open source library. The hash table approach also enables fast loading and expanding the reaction network. Reaction rules are read in by lines. Depending on how specifically the rules are described, each line of a reaction can be expanded into multiple elementary reactions. Since some binding sites can work independently from each other, rules can be described for necessarily relevant binding sites, without all possible combinations being specified. Instead, all possible combinations are expanded during loading the rules into the hash table. For example, for a bare cam binding with ca at an N1 site, it is not necessary to specify the states of C1 and
11
C2 sites. However, when parsing the reaction rule, the simulator automatically calculates all possible states of the involved reactant states. In this case, cam can be:
N1==0, N2==0, C1==0, C2==0, K==0, Kp==0, Ng==0
N1==0, N2==0, C1==0, C2==0, K==0, Kp==0, Ng==0
N1==0, N2==0, C1==1, C2==0, K==0, Kp==0, Ng==0
N1==0, N2==0, C1==1, C2==1, K==0, Kp==0, Ng==0
The syntax here allows a ”fuzzy” yet compact way to describe a reaction network, therefore avoids an issue of ”combinatorial explosion”, which is a common problem in systems biology when modeling and simulating macromolecules. In eukaryotic cells, macromolecules contain multiple binding sites and exhibit various binding states. These molecules are often modeled as multi-state systems. Depending on how the binding sites cooperate with each other, the total combinations of states can grow exponentially, resulting in problems to represent the states of a macromolecule (”the specification problem”) and to simulate the time evolution of the states (”the computation problem”). A common way to handle this problem is to follow a rule-based approach, which allows reaction rules to be described implicitly and avoid enumerating all possible combinations.


\subsection{compartment-dependent diffusion}









In a unoptimized sequence of additions, the sequence of operations is as
follows for each pair of numbers ($m_1$,$e_1$) and ($m_2$,$e_2$).
\begin{enumerate}
  \item Compare $e_1$ and $e_2$.
  \item Shift the mantissa associated with the smaller exponent $|e_1-e_2|$
        places to the right.
  \item Add $m_1$ and $m_2$.
  \item Find the first one in the resulting mantissa.
  \item Shift the resulting mantissa so that normalized
  \item Adjust the exponent accordingly.
\end{enumerate}

Out of 6 steps, only one is the actual addition, and the rest are involved
in aligning the mantissas prior to the add, and then normalizing the result
afterward.  In the block exponent optimization, the largest mantissa is
found to start with, and all the mantissa's shifted before any additions
take place.  Once the mantissas have been shifted, the additions can take
place one after another\footnote{This requires that for n consecutive
additions, there are $\log_{2}n$ high guard bits to prevent overflow.  In
the $\mu$FPU, there are 3 guard bits, making up to 8 consecutive additions
possible.}.  An example of the Block Exponent optimization on the expression
X = A + B + C is given in figure~\ref{opt:be}.

% This is an example of how you would use tgrind to include an example
% of source code; it is commented out in this template since the code
% example file does not exist.  To use it, you need to remove the '%' on the
% beginning of the line, and insert your own information in the call.
%
%\tgrind[htbp]{code/be.s.tex}{Block Exponent}{opt:be}

\section{Integer optimizations}

As well as the floating point optimizations described above, there are
also integer optimizations that can be used in the $\mu$FPU.  In concert
with the floating point optimizations, these can provide a significant
speedup.  

\subsection{Conversion to fixed point}

Integer operations are much faster than floating point operations; if it is
possible to replace floating point operations with fixed point operations,
this would provide a significant increase in speed.

This conversion can either take place automatically or or based on a
specific request from the programmer.  To do this automatically, the
compiler must either be very smart, or play fast and loose with the accuracy
and precision of the programmer's variables.  To be ``smart'', the computer
must track the ranges of all the floating point variables through the
program, and then see if there are any potential candidates for conversion
to floating point.  This technique is discussed further in
section~\ref{range-tracking}, where it was implemented.

The other way to do this is to rely on specific hints from the programmer
that a certain value will only assume a specific range, and that only a
specific precision is desired.  This is somewhat more taxing on the
programmer, in that he has to know the ranges that his values will take at
declaration time (something normally abstracted away), but it does provide
the opportunity for fine-tuning already working code.

Potential applications of this would be simulation programs, where the
variable represents some physical quantity; the constraints of the physical
system may provide bounds on the range the variable can take.
\subsection{Small Constant Multiplications}

One other class of optimizations that can be done is to replace
multiplications by small integer constants into some combination of
additions and shifts.  Addition and shifting can be significantly faster
than multiplication.  This is done by using some combination of
\begin{eqnarray*}
a_i & = & a_j + a_k \\
a_i & = & 2a_j + a_k \\
a_i & = & 4a_j + a_k \\
a_i & = & 8a_j + a_k \\
a_i & = & a_j - a_k \\
a_i & = & a_j \ll m \mbox{shift}
\end{eqnarray*}
instead of the multiplication.  For example, to multiply $s$ by 10 and store
the result in $r$, you could use:
\begin{eqnarray*}
r & = & 4s + s\\
r & = & r + r
\end{eqnarray*}
Or by 59:
\begin{eqnarray*}
t & = & 2s + s \\
r & = & 2t + s \\
r & = & 8r + t
\end{eqnarray*}
Similar combinations can be found for almost all of the smaller
integers\footnote{This optimization is only an ``optimization'', of course,
when the amount of time spent on the shifts and adds is less than the time
that would be spent doing the multiplication.  Since the time costs of these
operations are known to the compiler in order for it to do scheduling, it is
easy for the compiler to determine when this optimization is worth using.}.
\cite{magenheimer:precision}

\section{Other optimizations}

\subsection{Low-level parallelism}

The current trend is towards duplicating hardware at the lowest level to
provide parallelism\footnote{This can been seen in the i860; floating point
additions and multiplications can proceed at the same time, and the RISC
core be moving data in and out of the floating point registers and providing
flow control at the same time the floating point units are active. \cite{byte:i860}}

Conceptually, it is easy to take advantage to low-level parallelism in the
instruction stream by simply adding more functional units to the $\mu$FPU,
widening the instruction word to control them, and then scheduling as many
operations to take place at one time as possible.

However, simply adding more functional units can only be done so many times;
there is only a limited amount of parallelism directly available in the
instruction stream, and without it, much of the extra resources will go to
waste.  One process used to make more instructions potentially schedulable
at any given time is ``trace scheduling''.  This technique originated in the
Bulldog compiler for the original VLIW machine, the ELI-512.
\cite{ellis:bulldog,colwell:vliw}  In trace scheduling, code can be
scheduled through many basic blocks at one time, following a single
potential ``trace'' of program execution.  In this way, instructions that
{\em might\/} be executed depending on a conditional branch further down in
the instruction stream are scheduled, allowing an increase in the potential
parallelism.  To account for the cases where the expected branch wasn't
taken, correction code is inserted after the branches to undo the effects of
any prematurely executed instructions.

\subsection{Pipeline optimizations}

In addition to having operations going on in parallel across functional
units, it is also typical to have several operations in various stages of
completion in each unit.  This pipelining allows the throughput of the
functional units to be increased, with no increase in latency.

There are several ways pipelined operations can be optimized.  On the
hardware side, support can be added to allow data to be recirculated back
into the beginning of the pipeline from the end, saving a trip through the
registers.  On the software side, the compiler can utilize several tricks to
try to fill up as many of the pipeline delay slots as possible, as
seendescribed by Gibbons. \cite{gib86}


